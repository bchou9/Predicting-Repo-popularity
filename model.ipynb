{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It contains all operations for building a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing files/data from analysis.ipynb file for creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                           repo_name   star   fork watch  \\\n0                                              keras  47900  18100  2.1k   \n1                                       scikit-learn  40300  19600  2.2k   \n2                          PythonDataScienceHandbook  23100   9900  1.5k   \n3  Probabilistic-Programming-and-Bayesian-Methods...  21000   6600  1.4k   \n4                          Data-Science--Cheat-Sheet  18400   8200  1.5k   \n\n   issue      tags                                        description  \\\n0   2940  9.439798                           Deep Learning for humans   \n1   1505  6.048803           scikit-learn: machine learning in Python   \n2     65  2.463054  Python Data Science Handbook: full text in Jup...   \n3    127  1.752778  aka \"Bayesian Methods for Hackers\": An introdu...   \n4      7  0.000000                                       Cheat Sheets   \n\n   contributers                license  \\\n0            49           View license   \n1           108           View license   \n2             0           View license   \n3             0                    MIT   \n4             0  Fetching contributors   \n\n                                            repo_url    most_used_lang  \n0                https://github.com/keras-team/keras            Python  \n1       https://github.com/scikit-learn/scikit-learn            Python  \n2  https://github.com/jakevdp/PythonDataScienceHa...  Jupyter Notebook  \n3  https://github.com/CamDavidsonPilon/Probabilis...  Jupyter Notebook  \n4  https://github.com/abhat222/Data-Science--Chea...       no language  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repo_name</th>\n      <th>star</th>\n      <th>fork</th>\n      <th>watch</th>\n      <th>issue</th>\n      <th>tags</th>\n      <th>description</th>\n      <th>contributers</th>\n      <th>license</th>\n      <th>repo_url</th>\n      <th>most_used_lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>keras</td>\n      <td>47900</td>\n      <td>18100</td>\n      <td>2.1k</td>\n      <td>2940</td>\n      <td>9.439798</td>\n      <td>Deep Learning for humans</td>\n      <td>49</td>\n      <td>View license</td>\n      <td>https://github.com/keras-team/keras</td>\n      <td>Python</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scikit-learn</td>\n      <td>40300</td>\n      <td>19600</td>\n      <td>2.2k</td>\n      <td>1505</td>\n      <td>6.048803</td>\n      <td>scikit-learn: machine learning in Python</td>\n      <td>108</td>\n      <td>View license</td>\n      <td>https://github.com/scikit-learn/scikit-learn</td>\n      <td>Python</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PythonDataScienceHandbook</td>\n      <td>23100</td>\n      <td>9900</td>\n      <td>1.5k</td>\n      <td>65</td>\n      <td>2.463054</td>\n      <td>Python Data Science Handbook: full text in Jup...</td>\n      <td>0</td>\n      <td>View license</td>\n      <td>https://github.com/jakevdp/PythonDataScienceHa...</td>\n      <td>Jupyter Notebook</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Probabilistic-Programming-and-Bayesian-Methods...</td>\n      <td>21000</td>\n      <td>6600</td>\n      <td>1.4k</td>\n      <td>127</td>\n      <td>1.752778</td>\n      <td>aka \"Bayesian Methods for Hackers\": An introdu...</td>\n      <td>0</td>\n      <td>MIT</td>\n      <td>https://github.com/CamDavidsonPilon/Probabilis...</td>\n      <td>Jupyter Notebook</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data-Science--Cheat-Sheet</td>\n      <td>18400</td>\n      <td>8200</td>\n      <td>1.5k</td>\n      <td>7</td>\n      <td>0.000000</td>\n      <td>Cheat Sheets</td>\n      <td>0</td>\n      <td>Fetching contributors</td>\n      <td>https://github.com/abhat222/Data-Science--Chea...</td>\n      <td>no language</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description is also play a role in the popularity of your repos, so we need to clean  `description` tuple by removing punctuations and creating word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description']=data['description'].str.replace('\\W',\" \")\n",
    "data['description']=data['description'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating word count will require all unique words in the message(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description']=data['description'].str.split()\n",
    "vocabulary = []\n",
    "for sms in data['description']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['摘要相关工具',\n 'nlp',\n 'beta',\n 'inside',\n 'and',\n '09558',\n 'vehicles',\n 'event',\n 'scala',\n 'awsome']"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that their are some numerical values and stopwords too, so we need to remove them from vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [item for item in vocabulary if not item.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\TUSHAR\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopword=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for word in stopword:\n",
    "    if word in vocab:\n",
    "        vocab.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(data['description']) for unique_word in vocab}\n",
    "\n",
    "for index, lines in enumerate(data['description']):\n",
    "    for word in lines:\n",
    "        if word in vocab:\n",
    "            word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_col=pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing tuples that are required and concatenate both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['repo_name','license','repo_url','most_used_lang', 'watch', 'description'],axis=1,inplace=True)\n",
    "testing_set=pd.concat([data,word_col],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    star   fork  issue      tags  contributers  摘要相关工具  nlp  beta  inside  \\\n0  47900  18100   2940  9.439798            49       0    0     0       0   \n1  40300  19600   1505  6.048803           108       0    0     0       0   \n2  23100   9900     65  2.463054             0       0    0     0       0   \n3  21000   6600    127  1.752778             0       0    0     0       0   \n4  18400   8200      7  0.000000             0       0    0     0       0   \n\n   vehicles  ...  liquid  lists  旨在更好的日常管理和维护个人github  relating  orm  \\\n0         0  ...       0      0                     0         0    0   \n1         0  ...       0      0                     0         0    0   \n2         0  ...       0      0                     0         0    0   \n3         0  ...       0      0                     0         0    0   \n4         0  ...       0      0                     0         0    0   \n\n   messaging  activity  php资源大全中文版  微信小程序用户前端  apps  \n0          0         0           0          0     0  \n1          0         0           0          0     0  \n2          0         0           0          0     0  \n3          0         0           0          0     0  \n4          0         0           0          0     0  \n\n[5 rows x 3988 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>star</th>\n      <th>fork</th>\n      <th>issue</th>\n      <th>tags</th>\n      <th>contributers</th>\n      <th>摘要相关工具</th>\n      <th>nlp</th>\n      <th>beta</th>\n      <th>inside</th>\n      <th>vehicles</th>\n      <th>...</th>\n      <th>liquid</th>\n      <th>lists</th>\n      <th>旨在更好的日常管理和维护个人github</th>\n      <th>relating</th>\n      <th>orm</th>\n      <th>messaging</th>\n      <th>activity</th>\n      <th>php资源大全中文版</th>\n      <th>微信小程序用户前端</th>\n      <th>apps</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47900</td>\n      <td>18100</td>\n      <td>2940</td>\n      <td>9.439798</td>\n      <td>49</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40300</td>\n      <td>19600</td>\n      <td>1505</td>\n      <td>6.048803</td>\n      <td>108</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23100</td>\n      <td>9900</td>\n      <td>65</td>\n      <td>2.463054</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21000</td>\n      <td>6600</td>\n      <td>127</td>\n      <td>1.752778</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18400</td>\n      <td>8200</td>\n      <td>7</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3988 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LR can be used:\n",
    "# gradient descent\n",
    "# reandom forest \n",
    "# NN regression (Relu)\n",
    "# Lasso regression\n",
    "# Ridge regression\n",
    "# Elastic netregression\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}